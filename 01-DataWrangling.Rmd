# Everyday data wrangling

Suppose there exists a test dataset and the user is tasked with proving their proficiency in exploratory data analysis (EDA). Alternatively, the user may be handed a piece of data (e.g., maybe an Excel sheet) and is asked to run some preliminary analysis. Prior to jumping straight into EDA and statistical modeling, the user must be able to transform the original data into a desirable format. This includes, but is not limited to, missing data imputation, scalar transformation, feature selection, group aggregation, and data filtering. The following notebook outlines the fundamentals of data wrangling, using practical base R and `tidyverse` solutions interchangeably. 

```{r, warning=FALSE}
library(tidyverse)
```


## Renaming column headers

Suppose a `32 x 11` dataset `mtcars` where `rownames` correspond to the car model. 

```{r}
data(mtcars)
mtcars <- mtcars %>% as_tibble(rownames = 'CAR')
```

Renaming column headers with `dplyr::rename` is as simple as `rename(new_name = old_name)`, but with `rename_with()` there's more flexibility:

```{r}
mtcars %>% rename_with(toupper)
```

You can pass any function within `rename_with()` to alter the column headers and use the `.cols = ` argument to define which columns you'd apply the function to:

```{r}
mtcars %>% rename_with(function(x) paste0(x, "_1"), .cols = -1)
```

Alternatively with base R, you can call the `names` attribute and alter that directly:

```{r, eval=FALSE}
names(mtcars)[-1] <- paste0(names(mtcars[-1]), '_1') # not run
```


## Grouped operations

Grouped operations are most useful when you're working with data where there is a categorical variable. Grouped summaries are powerful tools easily done with `dplyr::summarise`:

```{r}
mtcars %>% group_by(cyl) %>% summarise(avg_mpg = mean(mpg))
```

Using multiple columns at once and renaming the output columns:

```{r}
mtcars %>% group_by(cyl) %>% 
  summarise(across(c(mpg, disp, hp), mean, .names = "mean_{col}"))
```

```{r}
mtcars %>% group_by(cyl) %>% 
  summarise(across(where(is.numeric), mean, .names = "mean_{col}"))
```

Alternatively, in base R, you can use `aggregate()` with the `~`; you can read this as *grouping mpg by cyl* where *by* corresponds to the `~`:

```{r}
aggregate(mpg ~ cyl, data = mtcars, FUN = mean)
```

When calculating the size of the groups, you can use `n()`:

```{r}
mtcars %>% group_by(cyl) %>% summarise(count = n())
```

Filtering by groups of size greater than a certain value:

```{r}
mtcars %>% group_by(cyl) %>% filter(n() > 7) %>% ungroup()
```


## Data transformation

Sometimes it's useful to transform numeric columns:

```{r}
mtcars %>% mutate(mpg = mpg*2)
```

Using `across()` allows for conditional transformation and keep the old columns, while renaming the new columns:

```{r}
mtcars %>% 
  mutate(across(where(is.numeric), function(x) x*2, .names = "double_{col}"))
```

You can overwrite the existing columns completely; also keep in mind that you can pass any function within `across()` as such:

```{r}
mtcars %>% mutate(across(c(mpg, disp), function(x) x*3))
```

Iterating across the columns using `purrr::modify` instead:

```{r}
mtcars %>% modify_if(is.numeric, ~ .x*3)
```

Mutating columns of characters is also straightforward:

```{r}
mtcars %>% mutate(CAR = gsub('Merc', 'Mercedes', CAR))
```

```{r}
mtcars %>% mutate(CAR = gsub(' ', '_', CAR)) %>% mutate(across(CAR, tolower))
```


## Joining and separating character columns

For the `CAR` column comprised of strings, you can separate the individual strings into multiple columns; the `extra = 'merge'` argument tells the function to separate the string based on the first instance of " " and merge the rest:

```{r, warning=FALSE}
mtcars %>% separate(CAR, c('Brand', 'Model'), sep = " ", extra = 'merge')
```

Combining multiple `tidyverse` verbs using the pipe `%>%`:

```{r, warning=FALSE}
mtcars %>% separate(CAR, c('Brand', 'Model'), sep = " ", extra = 'merge') %>%
  group_by(Brand) %>% summarise(count = n(), mean_mpg = mean(mpg)) %>%
  arrange(desc(count))
```

Note that the pipe `%>%` is part of the `magrittr` package but there's no need to load it after loading `tidyverse`. The pipe notation is frequently used between `tidyverse` verbs but you can also use it in some base R operations as well.

Separation of columns by strings, using base R instead involves using `strsplit()` which outputs a list and therefore we need to unpack it afterwards:

```{r, eval=FALSE}
mtcars$Brand <- unlist(
  lapply(strsplit(mtcars$CAR, split = ' '), function(x) x[1])
) # not run
mtcars$Model <- unlist(
  lapply(strsplit(mtcars$CAR, split = ' '), function(x) x[2])
) # not run
```

The opposite of `separate()` is `unite()` which combines columns into a single column:

```{r}
data(iris)
iris <- as_tibble(iris)
iris %>% unite('Petal.Dimensions', c(`Petal.Length`, `Petal.Width`),
               sep = " x ", remove = FALSE)
```

In base R, we create a new column using the `$` notation:

```{r, eval=FALSE}
iris$Petal.Dimensions <- paste(iris$Petal.Length, iris$Petal.Width, sep = " x ") # not run
```


## Filtering rows

Typically, filtering involves a condition based on a column to select the corresponding rows. Here I am combining `stringr::str_detect` with `dplyr::filter` since the column I am filtering on is a character vector.

```{r}
mtcars %>% filter(str_detect(CAR, 'Mazda'))
```

Combining `filter()` with `grepl()`:

```{r}
mtcars %>% filter(str_detect(CAR, 'Mazda | Merc'))
```

Ignoring upper/lower case distinction using `regex(..., ignore_case = TRUE)`:

```{r}
mtcars %>% filter(str_detect(CAR, regex('mazda', ignore_case = TRUE)))
```

Alternatively, using base R using `grepl()`:

```{r, eval=FALSE}
mtcars[grepl('Mazda', mtcars$CAR),] # not run
mtcars[grepl('Mazda|Merc', mtcars$CAR),] # not run
```

Using `tolower()` to make sure we're on the same page in regards to case:

```{r}
mtcars[grepl(tolower('Mazda'), tolower(mtcars$CAR)),]
```

Filtering rows based on a numeric column:

```{r}
mtcars %>% filter(between(mpg, 18, 20))
```

```{r}
mtcars %>% filter(cyl %in% c(6, 8))
```

Alternatively, in base R, using `which()`:

```{r, eval=FALSE}
mtcars[which(mtcars$mpg > 18 & mtcars$mpg < 20),] # not run
mtcars[which(mtcars$cyl %in% c(6,8)),] # not run
```


## Subsetting columns based on strings

Subsetting columns typically involves using square brackets `[ ]` in base R, but can be done easily with `dplyr::select`; `select()` supports multiple helper functions such as `starts_with()`, `ends_with()`, and `match()`.

```{r}
mtcars %>% select(contains('m'))
```

You can use multiple helper functions at once:

```{r}
mtcars %>% select(starts_with('m'), ends_with('c'))
```

Using regex, with the anchors `^` and `$`:

```{r}
mtcars %>% select(matches('^m'), matches('c$'))
```

Alternatively, in base R and regex:

```{r}
mtcars[,grepl('^m|c$', names(mtcars))]
```


## Long and wide data formats

Transforming datasets into long/wide formats is a typical task in EDA, and this can be done using `tidyr`:

```{r}
mtcars_long <- mtcars %>% pivot_longer(-1, names_to = 'Metric', values_to = 'Values')
mtcars_long
```

Having the dataset in this long format allows us to create visualizations such as the boxplot much easier. 

Pivoting the long format back to a wide format as also straightforward with `tidyr`:

```{r}
mtcars_wide <- mtcars_long %>% 
  pivot_wider(names_from = 'Metric', values_from = 'Values')
mtcars_wide
```

In base R, you can use `reshape()` with the argument `direction = ` but I don't find its syntax very intuitive. Alternatively, using `data.table` gets us the solution much easier:

```{r, warning=FALSE}
library(data.table)
melt(setDT(mtcars), id.vars = c('CAR'), variable.name = 'Metric')
```

Note that using `data.table` returns a `data.table` object (due to the `setDT()` function), which differs from the `tibble` we've been using for packages within `tidyverse`. There are some advantages to using `data.table` instead, especially when working with very large datasets. For the sake of this book I will mostly use base R and `tidyverse`, other than exceptional cases. 


## Trimming strings

Trimming character columns, then re-encoding them as factors:

```{r}
iris %>% mutate(Species = strtrim(Species, 3)) %>%
  mutate(Species = factor(Species, levels = c('set', 'ver', 'vir')))
```

Sometimes when you're importing datasets from external and/or untrustworthy sources (e.g., an Excel sheet) it's worth checking for any whitespaces. In that case you can use `stringr::str_trim` to remove all whitespaces prior to data analysis.

```{r}
iris %>% mutate(Species = str_trim(Species))
```


## Iterating over list of dataframes

Analogously to base R's `split`, using `group_split()` allows us to convert the dataset to a list based on a column; the length of this output list would correspond to the unique number of column entries:

```{r}
mtcars <- as_tibble(mtcars)
mtcars_lst <- mtcars %>% group_split(cyl)
```

Iteration will be covered in more detail in a future chapter, but using base R's `apply` family is straightforward. In this case since we're working with lists, we will use `lapply()` and pass a function (in this case, `rename_with()`):

```{r}
mtcars_lst <- lapply(mtcars_lst, function(x) 
  rename_with(x, function(y) paste0(y, "_", as.character(unique(x$cyl))), .cols = -1))
mtcars_lst[[1]]
```

A `tidyverse` alternative to `apply` is `purrr::map` and its variations:

```{r, warning=FALSE}
mtcars_lst <- mtcars %>% group_split(cyl)
mtcars_lst <- mtcars_lst %>% 
  map(~ rename_with(.x, function(y) paste0(y, "_", as.character(unique(.x$cyl))), 
                    .cols = -1))
mtcars_lst[[1]]
```

Fitting a linear model is easy using iterations; in this case we fit `lm()` on the variables `mpg` and `gear` to identify their relationship:

```{r}
mtcars_lst <- mtcars %>% group_split(cyl)
mtcars_lst %>% 
  map(~ lm(mpg ~ gear, data = .x)) %>%
  map(coef)
```

Using `broom::tidy` to clean up modelling result and output the model estimates:

```{r, warning=FALSE}
library(broom)
mtcars_lst %>%
  map(~ lm(mpg ~ gear, data = .x)) %>%
  map(tidy) %>%
  bind_rows()
```

Using base R and the `apply` family instead:

```{r}
models <- lapply(mtcars_lst, function(x) lm(mpg ~ gear, data = x))
coefs <- lapply(models, coef)
coefs[[1]]
```


## Rowwise operations

```{r}
df <- tibble(name = c('Brian', 'Connor'),
             coffee = sample(1:10, 2),
             wine = sample(1:5, 2),
             juice = sample(1:5, 2))
df
```

Sometimes it's useful to run calculations in a row-wise fashion; for example using `mutate()` with the helper function `c_across()`:

```{r}
df %>% rowwise() %>% mutate(total = sum(c_across(coffee:juice)),
                            avg = mean(c_across(coffee:juice)))
```

Calculating the proportions using a combination of row-wise and column-wise operations with `c_across()` and `across()`:

```{r}
df %>% rowwise() %>% mutate(total = sum(c_across(coffee:juice))) %>%
  ungroup() %>%
  mutate(across(coffee:juice, function(x) x/total,
                .names = "{col}_prop."))
```


## Conditional transformation

Conditional transformations are useful when creating categories based on a series of logical statements; this is done using `case_when()` to define the conditions:

```{r}
mtcars %>% mutate(mileage_class = 
  case_when(mpg > 20 ~ 'High',
            mpg < 20 ~ 'Low')) %>%
  relocate(mileage_class, .after = mpg)
```

In cases where we're working with character columns, it's useful to use `grepl` to match specific strings. After all, formula within `case_when()` needs to evaluate to a boolean on the left-hand side (e.g., `mpg > 20`). Additionally, in cases where the condition is not specified or met, you can use `TRUE ~ ` within `case_when()` as such:

```{r}
mtcars %>% mutate(CAR = case_when(grepl('Merc', CAR) ~ toupper(CAR), TRUE ~ CAR))
```

Conditional mutate using base R involves using `ifelse()`:

```{r}
mtcars$mileage_class <- ifelse(
  mtcars$mpg > 20, 'High', 'Low'
)
subset(mtcars, select = c(CAR, mpg, mileage_class, cyl:carb))
```


## Missing values

Handling missing values is tedious but often required when working with dodgy data.

First, for the sake of our exercise we insert NAs randomly in the `mtcars` dataset:

```{r}
mtcars_NA <- map_df(mtcars, function(x) 
  {x[sample(c(TRUE, NA), prob = c(0.95, 0.01), size = length(x), replace = TRUE)]})
mtcars_NA
```

Remove rows where any NA occurs:

```{r}
mtcars_NA %>% na.omit()
```

Identify columns with NAs and the number of occurrences:

```{r}
vapply(mtcars_NA, function(x) sum(is.na(x)), double(1))
```

Remove columns with more than one missing value: 

```{r}
mtcars_NA %>% select(where(function(x) sum(is.na(x)) < 1))
```

Replace missing values with zero using `tidyr::replace_na`: 

```{r, eval = FALSE}
mtcars_NA %>% map_dfc(~ replace_na(.x, 0))
```

Base R and using `is.na()` instead:

```{r, eval=FALSE}
mtcars_NA[is.na(mtcars_NA)] <- 0 # not run
```


## Joining dataframes

Mutating joins in `tidyverse` are analogous to the inner and outer joins in SQL syntax:

```{r}
df1 <- tibble(
  name = c('Brian', 'Connor', 'Jon'),
  city = c('Tokyo', 'London', 'Milan'),
  age = c(28, 25, 21)
)
df2 <- tibble(
  name = c('Brian', 'Connor'),
  hair = c('black', 'brown'),
  eyes = c('dark', 'hazel')
)
```

```{r}
df1 %>% inner_join(df2, by = 'name')
```

```{r}
df1 %>% left_join(df2, by = 'name')
```

Base R uses `merge()` with the argument `all.x = ` and `all_y = `:

```{r}
merge(df1, df2, by = 'name')
merge(df1, df2, by = 'name', all.x = TRUE)
```


